{"cells":[{"metadata":{},"cell_type":"markdown","source":"# UCI Medicine Review Analysis\n\n\n1. The goal of this project is to go through hands on analysis on UCI ML Drug Review dataset available through Kaggle. In particular, I want to address the following questions, (partly due to the similarity to a question that I am currently working on and the lack the proper data to learn):\n* What insights can we gain from exploring and visualizing our data?\n* How does sentiment play into rating and usefulness of reviews?\n* Can we create a way for people to find the best medication for their illness?\n* What machine learning models work best for predicting the sentiment or rating based on review?\n* Is this problem better suited for classification or regression? In other words, should we be trying to sort the reviews into categories based on sentiment or predict the actual rating of the review?\n* What vectorization methods for the reviews are the most efficient and preserve the most data as well as allowing for the most accuracy? \n* Can we somehow find insight into what features or words are most important for predicting review rating?"},{"metadata":{},"cell_type":"markdown","source":"## 1. Getting Started: Basic EDA"},{"metadata":{"id":"Aql6hMARUUqB"},"cell_type":"markdown","source":"1. Read in the data sets\n2. What are the columns, dimentions, missing data\n3. why they were pre-set into test & train: are there any major differences"},{"metadata":{"id":"u_0Ld9oZUUp5","outputId":"05bfa3e9-2421-4a60-ef5b-9a6cb6c75757","trusted":true},"cell_type":"code","source":"#import libraries\nimport numpy as np\nimport pandas as pd\n#for NLP:\nimport spacy\n# Load English tokenizer, tagger, parser, NER and word vectors\nnlp = spacy.load(\"en_core_web_sm\")\n# Word tokenization #lemma\nfrom spacy.lang.en import English,stop_words \n#word viz\nfrom spacy import displacy \nimport string\n#for the Pipiline\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.base import TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom gensim.models import Word2Vec\n\nfrom matplotlib import pyplot as plt # viz\n%matplotlib inline\n\n#to display entire text \npd.set_option('display.max_colwidth', None)","execution_count":null,"outputs":[]},{"metadata":{"id":"trrXt_xqUUqC","trusted":true},"cell_type":"code","source":"#Read in the data\n#convert date into correct format\n\ntrain = pd.read_csv('../input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv',  parse_dates=[\"date\"]) \ntest = pd.read_csv('../input/kuc-hackathon-winter-2018/drugsComTest_raw.csv',  parse_dates=[\"date\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"cpogUUUSUUqJ","outputId":"0d99adf6-25a0-4e75-9b34-00c0919ff299","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"-h6rhUu0UUqT","outputId":"1075c44e-d0ad-49a9-9a04-638457ef362a","trusted":true},"cell_type":"code","source":"#shape of train data, columns\nprint(train.shape)\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"b73J-_XyUUqd","outputId":"a14d820f-5139-478e-f039-2238e03ead00","trusted":true},"cell_type":"code","source":"#shape of test data, columns\nprint(test.shape)\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train and test share same columns\nlist(train) == list(test)","execution_count":null,"outputs":[]},{"metadata":{"id":"P-9rPZSVUUqm","outputId":"25a76d72-1b7b-4ff7-fb0c-116d79ceffc3","trusted":true},"cell_type":"code","source":"#missing values\ntrain.isnull().sum()/train.shape[0],test.isnull().sum()/test.shape[0]\n\n# only 0.5% of the data in both sets along the condition feature. \n# if the drug is available in the data set - the condition can be extrapolated\n# else with such a small number - it can be exluded","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"HgSBq-9XUUqu","outputId":"c71c651a-6708-4680-ef4d-eed50f6d8c68","trusted":true},"cell_type":"code","source":"#what drugs with missing conditions are missing and how to resolve it \ndrugNoCond = train[train.condition.isnull()].drugName.unique()\nprint('Number of drugs with no condition description: ',len(drugNoCond))\nprint('Number of drugs that have no records with conditions at all:',\nlen(set(train[train.condition.isnull()].drugName) - set(train.drugName)))","execution_count":null,"outputs":[]},{"metadata":{"id":"SsmMgAIXUUqz","outputId":"f7207d2e-ecc4-416a-a750-ab5b2830676b","trusted":true},"cell_type":"code","source":"#are there drugs with multiple conditions?\ntrain.groupby('drugName').condition.nunique().mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"HxZjxYI3UUq2","outputId":"b56eb3be-e8db-4cce-ff11-d41ad69d5083","trusted":true},"cell_type":"code","source":"#create a unique drug - condition list\ndrugCond = train[['drugName','condition']].drop_duplicates()\n#check how many conditions have the drugs with missing ones\ndrugCond[drugCond.drugName.isin(drugNoCond)].groupby('drugName').condition.count().mean()\n\n#cannot replace missing condition","execution_count":null,"outputs":[]},{"metadata":{"id":"bIN6m_KSUUq8","outputId":"920b4322-2d49-4aaa-fa21-25771322b180","trusted":true},"cell_type":"code","source":"#3\n#what drugs are available in each set\nprint('Drugs in the train set: {}, test set: {}'.format(train.drugName.nunique(),test.drugName.nunique()))\n#how many reviews per drug on average\nprint('average reviews per drug')\nprint(round(train.groupby('drugName').review.count().mean(),2),',',round(test.groupby('drugName').review.count().mean(),2))\n\n#how many intersect in both sets\nprint('Drugs in train not in test: ',len(list(set(train.drugName.unique())-set(test.drugName.unique()))))\nprint('It is ',len(list(set(train.drugName.unique())-set(test.drugName.unique())))/len(train.drugName.unique()),'% of train')\nprint('Drugs in test not in train: ',len(list(set(test.drugName.unique())-set(train.drugName.unique()))))\nprint('It is ',len(list(set(test.drugName.unique())-set(train.drugName.unique())))/len(test.drugName.unique()),'% of test')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"QKqxxqg0UUrA","outputId":"9b61bff9-b86f-4563-f37d-851aefab7658","trusted":true},"cell_type":"code","source":"#are there any time differences\nprint('train date range: ', train.date.min(), train.date.max())\nprint('test date range: ', test.date.min(), test.date.max())\n#same","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"Zxw96NBxUUrF","outputId":"0257faba-c1e7-4266-e3df-e15ee558cbca","trusted":true},"cell_type":"code","source":"#that is a weird data split\n#join it back together\n#delete the rows with missing condition\nfull_set = pd.concat([train,test])\nfull_set = full_set[~full_set.condition.isnull()]\nfull_set.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"iLb0_EkfUUrK","outputId":"9de066fe-8353-4e03-985b-fbd5e9ad2626","trusted":true},"cell_type":"code","source":"#how many drugs in total\nprint('Total drugs in the set ',full_set.drugName.nunique())\n#how many conditiosn in total\nprint('Total conditions in the set ',full_set.condition.nunique())","execution_count":null,"outputs":[]},{"metadata":{"id":"fEOXjm-kUUrO","outputId":"48d94f35-fc45-4ad4-f1ad-981e18cbab5d","trusted":true},"cell_type":"code","source":"#what is the drug count per condition?\nprint('Average drugs per condition ',full_set.groupby('condition').drugName.nunique().mean())\nfull_set.groupby('condition').drugName.nunique().sort_values(ascending = False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"id":"flaL7Q5sUUrR","outputId":"61cd68dc-d1a6-4425-b3fe-72a66f17bb42","trusted":true},"cell_type":"code","source":"#any condition/drug with special characters?\n#exclude space and fw slash\n#has ')' and '<' #173 rows\nprint('Percent of error text in condition: ', full_set[(~full_set.condition.str.isalnum())&(~full_set.condition.str.contains('/| |-|,'))].\\\n                                              shape[0]/full_set.shape[0])\nprint('Percent of \"NOT LISTED\" condition: ', full_set[full_set.condition==\"Not Listed / Othe\"].shape[0]/full_set.shape[0])\nprint('Percent of error text in drug: ', full_set[(~full_set.drugName.str.isalnum())&(~full_set.drugName.str.contains('/| |-|,'))].\\\n                                              shape[0]/full_set.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"MHFF6FbyUUrV","outputId":"f261e603-4e5e-49fa-e9d7-641d0e9343bf","trusted":true},"cell_type":"code","source":"#All the issues will affect further analysis and cannot be fixed \n#they make up to 2% of the data \n# delete rows\n\n#if condition has special char like ) or <\n#if condition in \"NOT LISTED\"\n\nprint(full_set.shape[0])\nfull_set = full_set[~full_set.condition.str.contains('\\<|\\?|\\)|\\(')]\nprint(full_set.shape[0])\nfull_set = full_set[full_set.condition!=\"Not Listed / Othe\"]\nprint(full_set.shape[0])\nprint('final set to initial data is ',full_set.shape[0]/(train.shape[0]+test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"id":"hPkTREARUUrZ","trusted":true},"cell_type":"code","source":"#create couple of useful columns for visualizations and further analysis\nfull_set.loc[full_set.rating<4,'rating_group']  = '-1'\nfull_set.loc[full_set.rating.between(4,8),'rating_group']  = '0'\nfull_set.loc[full_set.rating>=8,'rating_group']  = '1'\n\nfull_set['year'] = full_set['date'].dt.year","execution_count":null,"outputs":[]},{"metadata":{"id":"9a1izg03UUrf"},"cell_type":"markdown","source":"## 2. Data Visualizaton\n"},{"metadata":{"id":"QAAQUyP-UUrg","trusted":true},"cell_type":"code","source":"#Top 10 reviewed & rated drugs\ntop_drugs = full_set.groupby('drugName').agg({'rating':['count','mean']}).reset_index()\ntop_drugs.columns = ['drugName','rating_count','rating_mean']\ntop_reviewed = top_drugs.sort_values(by = 'rating_count').tail(10)\ntop_rated = top_drugs[top_drugs.rating_count>50].sort_values(by = ['rating_mean']).tail(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"IAhoToKzUUrj","outputId":"b9a7bc12-5013-4bb7-88a8-5a572f13c161","trusted":true},"cell_type":"code","source":"top_reviewed.plot(kind='barh',y='rating_count',x='drugName',color='r',\\\n                 title = 'Top most reviewed drugs');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"fWuG4hiRUUrm","outputId":"6e6e6460-5c00-40e8-fc17-53d659c407bf","trusted":true},"cell_type":"code","source":"top_rated.plot(kind='barh',y='rating_mean',x='drugName',color='b',\\\n              title = 'Top rated drugs with more than 50 reviews');","execution_count":null,"outputs":[]},{"metadata":{"id":"0LFQDvByUUrq","trusted":true},"cell_type":"code","source":"#Top 10 reviewed & rated conditions\ntop_cond = full_set.groupby('condition').agg({'rating':['count','mean']}).reset_index()\ntop_cond.columns = ['condition','rating_count','rating_mean']\ntop_reviewed_cond = top_cond.sort_values(by = 'rating_count').tail(10)\ntop_rated_cond = top_cond[top_cond.rating_count>50].sort_values(by = ['rating_mean']).tail(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"4HcL5-6hUUrt","outputId":"31ec419b-9da4-42e5-e383-89b4ccd2fc96","trusted":true},"cell_type":"code","source":"top_reviewed_cond.plot(kind='barh',y='rating_count',x='condition',color='r',\\\n                 title = 'Top conditions with most drug reviews');","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"Ua0b_tIRUUrx","outputId":"93d52b52-b0b3-4735-b61b-e25f8c9c5c8f","trusted":true},"cell_type":"code","source":"top_rated_cond.plot(kind='barh',y='rating_mean',x='condition',color='r',\\\n                 title = 'Top conditions with highest treatment ratings');","execution_count":null,"outputs":[]},{"metadata":{"id":"6kuLHOu1UUr0","outputId":"16e763a5-d52f-4358-df81-2766d4cbc6d6","trusted":true},"cell_type":"code","source":"#do people tend to leave more negative or positive reviews\nfull_set.groupby('rating_group').review.count()/full_set.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"CYIQRq51UUr3","outputId":"935468dd-5ea8-4b26-fbf6-8f9c5b976f92","trusted":true},"cell_type":"code","source":"#rating distro\nfull_set.rating.plot(kind = 'hist');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a list (cast into an array) containing the average usefulness for given ratings\nuse_ls = []\n\nfor i in range(1, 11):\n    use_ls.append([i, np.sum(full_set[full_set.rating == i].usefulCount) / np.sum([full_set.rating == i])])\n    \nuse_arr = np.asarray(use_ls)","execution_count":null,"outputs":[]},{"metadata":{"id":"sTsJCaoSUUr8","trusted":true},"cell_type":"code","source":"# #correlation btween usefulness and rating\nplt.scatter(use_arr[:, 0], use_arr[:, 1], c=use_arr[:, 0], cmap='tab10', s=200)\nplt.title('Average Useful Count vs Rating')\nplt.xlabel('Rating')\nplt.ylabel('Average Useful Count')\nplt.xticks([i for i in range(1, 11)]);\n\n#positive reviews have higher chanse to be considered useful","execution_count":null,"outputs":[]},{"metadata":{"id":"md7_v2qOUUr_","outputId":"3ae954f4-1852-4e07-e8c5-fb5f4899cb0e","trusted":true},"cell_type":"code","source":"#correlation btween usefulness and review length\nx = full_set['review'].str.len()\ny = full_set['usefulCount']\nsize = full_set['rating']\nplt.scatter(x,y,s = size , alpha=0.5); #, c = full_set['rating_group']\nplt.xlabel(\"log of review char length\");\nplt.ylabel(\"usefulness\");\nplt.xscale('log');\n#seems like too long or too short reviews are less useful\n#reviews between 100 - 1000 char are most useful - or at least most readable","execution_count":null,"outputs":[]},{"metadata":{"id":"irf4hbrIUUsD","outputId":"ad5727bd-b857-4121-9b50-295b380ca823","trusted":true},"cell_type":"code","source":"# #reviews by year\ncounts = full_set.groupby('year').review.count().reset_index()\nplt.bar(x = counts['year'], height = counts['review']);\nplt.title('Review count by year');","execution_count":null,"outputs":[]},{"metadata":{"id":"LbN9rQY6UUsG"},"cell_type":"markdown","source":"## 3. Sentiment analysis"},{"metadata":{"id":"FMaunVWlUUsQ"},"cell_type":"markdown","source":"#### 3.1 Predict rating based on review\n* Built the model for sentiment analysis\n*  Evaluating the Model\n* Check few models:\n1. One vs Rest\n2. SVC\n3. Simple NN\n\n\n\nAfter the model is trained test data through the pipeline to come up with predictions. \n\n<!-- Check performance of the model using such metrics as model’s accuracy, precision, and recall.\n\n* *Accuracy* refers to the percentage of the total predictions our model makes that are completely correct.\n* *Precision* describes the ratio of true positives to true positives plus false positives in our predictions.\n* *Recall* describes the ratio of true positives to true positives plus false negatives in our predictions. -->"},{"metadata":{"id":"ISQrcQXrUUsQ","trusted":true},"cell_type":"code","source":"#Load stop words\nstopwords = stop_words.STOP_WORDS\n# Create our list of punctuation marks\npunctuations = string.punctuation\n# Load English tokenizer, tagger, parser, NER and word vectors\nparser = English()","execution_count":null,"outputs":[]},{"metadata":{"id":"9UiUc-2_UUsV","trusted":true},"cell_type":"code","source":"#since we are doing sentiment analysis on review positivity, it makes sence to keep negative stop words\nstopwords = stopwords - set([\"n't\",'none','not', 'nothing','n‘t', 'n’t', 'no'])","execution_count":null,"outputs":[]},{"metadata":{"id":"pM1fmq3lUUsY","outputId":"8cb95687-3371-41c8-e6d6-d993d4795fdd","trusted":true},"cell_type":"code","source":"full_set.review.head(3)\n# looks like ' is replaced by &#039; - need to clean","execution_count":null,"outputs":[]},{"metadata":{"id":"YxV8mBS_UUsc","trusted":true},"cell_type":"code","source":"#create custom tokennizer\ndef spacy_tokennizer(sent):\n    #removing the &#039; combo:\n    sent = sent.replace('&#039;',\"'\").replace('&quot;', '').replace('&amp;', '')\n    #create token object\n    parsed = nlp(sent)\n    token_list = []\n    for word in parsed:\n        # Removing stop words\n        if (word.lemma_ not in stopwords) and (word.lemma_ not in punctuations) and (word.pos_ !='PRON'):\n            # Lemmatizing each token and converting each token into lowercase\n            w=word.lemma_.lower().strip()\n            token_list.append(w)\n            \n    # return preprocessed list of tokens\n    return token_list","execution_count":null,"outputs":[]},{"metadata":{"id":"D0fUpGA0UUsj","trusted":true},"cell_type":"code","source":"#split data into test and train\nX = full_set['review']\ny = full_set['rating_group']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 33)","execution_count":null,"outputs":[]},{"metadata":{"id":"lIlDCWOqUUsn","trusted":true},"cell_type":"code","source":"#1 One vs Rest\npipeline_lg = Pipeline([\n            ('vectorizer', CountVectorizer(tokenizer=spacy_tokennizer, ngram_range=(3,5))),\n            ('tfidf', TfidfTransformer()),\n            ('classifier', OneVsRestClassifier(SGDClassifier(loss='modified_huber', penalty='elasticnet',\n                                          alpha=1e-4, random_state=42,\n                                          shuffle=True, n_jobs=-1) )),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"id":"mqKLmvhrUUsr","outputId":"562d0656-59f8-4e44-d147-4ef6a662d9ec","trusted":true},"cell_type":"code","source":"pipeline_lg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"8evm_eFqUUsw","outputId":"22308c6a-9c31-4f3f-8456-471af5b69c03","trusted":true},"cell_type":"code","source":"y_pred  = pipeline.predict(X_test)\n\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"k_OcXOgjUUs5","trusted":true},"cell_type":"code","source":"#2 SVC\n# param_grid = {'C':np.arange(0.01,100,10)}\n# clf = GridSearchCV(\n#     svm.LinearSVC((), param_grid,cv =5)\n\npipeline_svm = Pipeline([\n            ('vectorizer', CountVectorizer(tokenizer=spacy_tokennizer, ngram_range=(1,4))),\n            ('tfidf', TfidfTransformer()),\n            ('classifier', svm.LinearSVC()),\n        ])\n#","execution_count":null,"outputs":[]},{"metadata":{"id":"hS6a5B-VUUtD","outputId":"39ad029f-e58e-4ea0-ce5b-da4d48c9dda7","trusted":true},"cell_type":"code","source":"pipeline_svm.fit(X_train,y_train)\n#print(\"Best estimator found by grid search:\")\n#print(pipeline_svm.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"id":"Y3OMy2lnUUtJ","outputId":"9e1410cd-6fb6-47fb-c7fb-188dc0ebd210","trusted":true},"cell_type":"code","source":"y_pred_svm  = pipeline_svm.predict(X_test)\nprint(classification_report(y_test,y_pred_svm))","execution_count":null,"outputs":[]},{"metadata":{"id":"z1jWN_GnT_xj","outputId":"8b7d9153-ec77-47ad-9750-4f95f52322f6","trusted":true},"cell_type":"code","source":"#3 NN\n#Instead of using pipeline, need to enumerate the input first\nX_full = pd.concat([X_train,X_test])\ntr_shape = X_train.shape[0]\nprint(X_train.shape[0])\nprint(X_full.shape[0])\ny_full = pd.concat([y_train,y_test])\n\nvectorizer = CountVectorizer(binary=True, stop_words=stopwords,\n                             lowercase=True, max_features=5000)\nX_onehot = vectorizer.fit_transform(X_full)\nprint(X_onehot.toarray())\n\nnames_list = vectorizer.get_feature_names()\nnames = [[i] for i in names_list]\nnames = Word2Vec(names, min_count=1)\nprint(len(list(names.wv.vocab)))\nprint(list(names.wv.vocab)[:5])\n\ny_onehot= keras.utils.to_categorical(y_full,3)\nprint(y_onehot)","execution_count":null,"outputs":[]},{"metadata":{"id":"dyI0spALsNHY","outputId":"086dfaf3-98ee-483a-ef84-ba29ed5b912e","trusted":true},"cell_type":"code","source":"#check which position is which type of rating\nprint(y_full[-2:-1])\nprint(y_onehot[-2:-1])\nprint(\"---\")\nprint(y_full[-1:])\nprint(y_onehot[-1:])\nprint(\"---\")\nprint(y_full[-4:-3])\nprint(y_onehot[-4:-3])","execution_count":null,"outputs":[]},{"metadata":{"id":"8b3CIxpxUUtS","outputId":"1fe9d23d-eff6-4afd-fafe-7cba8af97658","trusted":true},"cell_type":"code","source":"\n# # Separate data and one-hot encode the output\n# # Note: We're also turning the data into numpy arrays, in order to train the model in Keras\nX_train = X_onehot[:tr_shape]\nX_test = X_onehot[tr_shape:]\ny_train = y_onehot[:tr_shape]\ny_test = y_onehot[tr_shape:]\n\nfeatures = np.array(X_train)\ntargets = np.array(y_train)\nfeatures_test = np.array(X_test)\ntargets_test = np.array(y_test)\n\nmodel = Sequential()\nmodel.add(Dense(64,  input_shape=(X_train.shape[1],)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(32))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(3, activation='softmax'))\n\n# Compiling the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"PEtPZSFUllfh","outputId":"ff3f6ece-5a98-4057-c17d-69a38abf23da","trusted":true},"cell_type":"code","source":"# Training the model\nmodel.fit(X_train, y_train, epochs=200, batch_size=5000, verbose=0)\n\nscore = model.evaluate(X_train, y_train, verbose=0)\nprint(\"TRAIN Accuracy: \", score[1])\n\n ## 6. Evaluating the model\n #This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint(\"TEST Accuracy: \", score[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"tWPGW0k69vjP"},"cell_type":"markdown","source":"####  Evaluating the Model\nAfter the model is trained test data through the pipeline to come up with predictions. Check performance of the model using such metrics as model’s accuracy, precision, and recall.\n\n* *Accuracy* refers to the percentage of the total predictions our model makes that are completely correct.\n* *Precision* describes the ratio of true positives to true positives plus false positives in our predictions.\n* *Recall* describes the ratio of true positives to true positives plus false negatives in our predictions.\n\n### Medicine Recommendation System\n* The original idea was to find another dataset with medicine ingredient list and provide a personalised recommedation based on user previous history (alergies, side effects) or based on possible negative side effects of adding a new drug to existing prescriptions. However, I was not able to find a dataset that would provide enough information to implement this.\n* This is a simple recommender system based on medicine rating and prevalance\n\nThe data has columns rating, usefulCount and date. I want to use all three to sort the drugs for recommendation. To create a list of drugs for each condion\n    * a small coefficient is applied to the rating depending how old the review is to favor recent reviews\n    * another coefficient is applied to the rating based on the usefulness to favor more useful reviews\n    * the rating mean is calculated for each drug & condition\n\n"},{"metadata":{"id":"on06HX0S96H7","trusted":true},"cell_type":"code","source":"def simple_recommender_with_adj(c, n = 10,df = full_set):\n    '''\n    input:\n    c - illness/disorder/condition\n    n - number of requested drugs\n    df - data set to work with\n    \n    output - recommended top n treatment drugs \n    '''\n    alpha =  df.year/df.groupby('condition').year.transform('max') #adjustment for review age\n    beta  =   (df.usefulCount/df.groupby('condition').usefulCount.transform('max')).fillna(0)\n    \n    df['rating_adj'] = (df.rating*alpha +beta)*10/(np.max(df.rating*alpha +beta)) #normalizing back to 10 point scale\n    \n    #filter for conditions with at least three drugs & at least 5 reviews\n    cond = df.groupby('condition').drugName.count()\n    rev =  df.groupby('drugName').review.count()\n    rec_set = df[(df.condition.isin(cond[cond>2].index))&(df.drugName.isin(rev[rev>5].index))]\n    \n\n    rec_set = rec_set.groupby(['condition','drugName']).rating_adj.mean().reset_index().\\\n                sort_values(by = ['condition', 'rating_adj'], ascending = False)\n    final = rec_set.loc[rec_set.condition ==c,['drugName','rating_adj']].drop_duplicates().reset_index()\n    return final.drugName.head(n)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"5WT9a-YagCim","outputId":"5344769b-830e-4d00-d320-a77ab281981c","trusted":true},"cell_type":"code","source":"simple_recommender_with_adj('Acne',10)","execution_count":null,"outputs":[]},{"metadata":{"id":"_Y_KR97ZqJn1","trusted":true},"cell_type":"code","source":"def sentiment_recommender(c,d,r, df = full_set, vectorizer = vectorizer):\n    '''\n    input:\n    c - illness/disorder/condition\n    d - drug\n    r - patient review\n    n - number of requested drugs\n    df - full set from earlier\n    vectorizer - from the sentiment analysis\n    \n    output - recommended top n treatment drugs \n    '''\n    # check a new review rating:\n    #turn string into series\n    r = pd.Series(r)\n    new_one_hot = vectorizer.transform(r)\n    #model.predict(new_one_hot)  # [neutral, positive, negative]\n    pos = np.argmax(model.predict(new_one_hot))\n    rec = simple_recommender_with_adj(c)\n    #get drug index\n    ind = rec.index[rec==d].to_numpy()[0] \n    if pos ==1:\n      #positive review\n      print('It is wonderful you are happy with your meds.')\n      if ind >0:\n        #exclude the current drug from the list\n        print(\"Here are some other great meds to keep in mind\")\n      rec = rec[rec != d].head(3)\n      \n    else :\n      #negative/ neutral review\n      print(\"Looks like the medicine didn't satisfy your needs.\" )\n      print(\"Here is what you can consider\")\n\n      #get current drug index and recomment only ones that are ranked higher\n      #return top 5\n      if ind >0:\n        rec = rec[rec.index<ind].head(5)\n      #if index == 0\n      #recomend the next two\n      else:\n        rec = rec[rec != d].head(2)\n    return rec.values","execution_count":null,"outputs":[]},{"metadata":{"id":"G0le19gRqJca","outputId":"a0078839-a076-4966-8adc-ae1b4ec87c48","trusted":true},"cell_type":"code","source":"r = 'Not working'#'wonderful amazing works like a charm'\nd = 'Bactrim'\nc = 'Acne'\n\nsentiment_recommender(c,d,r)","execution_count":null,"outputs":[]},{"metadata":{"id":"nkNjZsdx_nVF"},"cell_type":"markdown","source":"## Medicine similarity\nWhat Meds are more similar to each other.\nCan it be wrapped in to another recommender?\n"},{"metadata":{"id":"U1z65ww7_m_-","outputId":"e92fb016-abf7-4d2a-cf13-14278456273d","trusted":true},"cell_type":"code","source":"#there are total 3635 drugs - that is quite a lot. how many only have less than 10 reviews?\nmed_counts = full_set.groupby('drugName').review.nunique().\\\n                    sort_values(ascending = False).reset_index().rename(columns = {'review':'COUNTS'})\n\nmed_counts.shape[0] - med_counts[med_counts.COUNTS<=10].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"ob_YuoLz_m7W","outputId":"61d8deff-b69e-4a87-f2a0-8665ad39838e","trusted":true},"cell_type":"code","source":"# filter to more than 20 reviews per drug\n# and for useful count >50\nkeep = (full_set.groupby('drugName').review.nunique()>20).reset_index()\nkeep =keep[keep.review == True].drugName.values\n\n#combine all reviews by  count>20 per drug\nall_revs =full_set[(full_set.drugName.isin(keep))&(full_set.usefulCount>50)]\ndrugs= all_revs['drugName'].unique()\nprint('drug ',drugs.shape[0])\nreviews = all_revs.groupby(['drugName'])['review'].agg(lambda col: ''.join(col)).reset_index()\nprint('reviews ',reviews.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"-S7ofAY7AAaN","trusted":true},"cell_type":"code","source":"#Create a similarity matrix for drugs\ndef create_similarity_matrix( df = reviews):\n      '''\n    input:\n    c - illness/disorder/condition\n    d - drug\n    n - number of requested drugs\n    df - reviews df filtered by review count & useful count criteria\n    \n    output - recommended top n treatment drugs \n    '''\n\n    #df = df[df.drugName == d]\n    drugs = df.drugName.unique()\n    vectorizer = TfidfVectorizer(stop_words=stopwords, ngram_range=(1,4))\n    X = vectorizer.fit_transform(df['review'].tolist())\n     \n    similarity_matrix = pd.DataFrame(linear_kernel(X, X), index = drugs, columns =drugs)\n    return similarity_matrix","execution_count":null,"outputs":[]},{"metadata":{"id":"OebEcOMEw2WF","trusted":true},"cell_type":"code","source":"def similarity_matrix_recommender(d,c,n=10,df = reviews, all_revs = all_revs):\n    '''\n    input:\n    c - illness/disorder/condition\n    d - drug\n    n - number of requested drugs\n    df - reviews df filtered by review count & useful count criteria from earlier\n    all_revs - df where drug has a single row with all reviews combined together\n    output - recommended top n treatment drugs \n    '''\n    drug_matrix = create_similarity_matrix()[d].sort_values(ascending = False)\n    #get top n closely matching drugs\n    final = all_revs[(all_revs.drugName.isin(drug_matrix.index[1:n]))&(all_revs.condition==c)].groupby(['drugName','condition']).rating.mean()\n    final = final.sort_values(ascending = False).reset_index()\n    #final.drugName.values\n    return final","execution_count":null,"outputs":[]},{"metadata":{"id":"UY6kRrdmypg7","outputId":"04875ffd-0b63-4688-bf95-386bb6af461b","trusted":true},"cell_type":"code","source":"d = 'Accutane'\nc = 'Acne'\nn = 10\nsimilarity_matrix_recommender(d,c,n)","execution_count":null,"outputs":[]},{"metadata":{"id":"HkQOZMpQ8Fl_","outputId":"28cdbdf7-8755-42ca-baef-3631d5502ac0","trusted":true},"cell_type":"code","source":"d = None\n\nd==None","execution_count":null,"outputs":[]},{"metadata":{"id":"lWyslxnf7fIS","trusted":true},"cell_type":"code","source":"#combine all together\ndef medicine_recommender(c, d = None, r= None, n = 3, df = full_set):\n  '''\n  input:\n  c - condition patient is diagnosed with\n  d - drug name, if currently using any\n  r - patients review/ feedback\n\n  output: top n drugs to try\n  '''\n  #case 1 - new diagnosis\n  #use simple recommender\n  if d==None:\n    rec = simple_recommender_with_adj(c,n)\n\n  #if patient has a history of drugs.\n  #get drug review (d,r)\n  #use sentiment recommender\n  else:\n    rec = sentiment_recommender(c,d,r)\n  return rec","execution_count":null,"outputs":[]},{"metadata":{"id":"W33TjzIiBZ8b","outputId":"5ed81a72-23de-42f9-a7b8-9566e1e872ae","trusted":true},"cell_type":"code","source":"c = 'Acne'\nd = 'Bactrim'\nr = 'Slowly working. Terrible side effects'\nmedicine_recommender(c, d = d, r= r, n = n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}